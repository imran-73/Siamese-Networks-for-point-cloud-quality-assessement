{"cells":[{"cell_type":"code","execution_count":null,"id":"aac0dfba","metadata":{"id":"aac0dfba"},"outputs":[],"source":["import open3d as o3d\n","import tensorflow as tf\n","import numpy as np\n","import os\n","from utilities import *\n","import re\n","import scipy\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import random\n","from pyntcloud import PyntCloud\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","from plyfile import PlyData, PlyElement\n","from scipy.spatial import cKDTree\n","from tqdm.notebook import tqdm, trange\n","from multiprocessing import Pool"]},{"cell_type":"code","execution_count":null,"id":"1a4a362b","metadata":{"id":"1a4a362b"},"outputs":[],"source":["initial_path = r'write the path where you put the project'\n","db_path = os.path.join(initial_path, r'icip2020_perry_quality_repack_bin')\n","deg_metrics_path = os.path.join('data', 'icip2020_deg_metrics.json')\n","degraded_pcs_features_path = os.path.join('data', 'icip2020_degraded_pcs_features.csv')\n","degraded_pcs_features_preds_path = os.path.join('data', 'icip2020_degraded_pcs_features_preds.csv')\n","block_bits = 6\n","block_shape = [2**block_bits] * 3\n","bbox_min = [0,0,0]"]},{"cell_type":"code","execution_count":null,"id":"35237644","metadata":{"id":"35237644"},"outputs":[],"source":["df = pd.read_csv(os.path.join(db_path, 'dataset.csv'))\n","pc_names = df['pc_name'].unique()\n","df = df.set_index(['pc_name', 'codec_id', 'codec_rate']).sort_index()"]},{"cell_type":"code","execution_count":null,"id":"f3ffa7fd","metadata":{"id":"f3ffa7fd"},"outputs":[],"source":["icip_pcs = []\n","for idx, data in tqdm(df.iterrows()):\n","    icip_pcs.append(icip_pc(idx[0],idx[1],idx[2],data['geometry_bits'],data['mos'],data['mos_ci'],data['relative_path'],data['radius']))       \n","for pc in tqdm(icip_pcs):\n","    pc.load_points()\n","    pc.connect_with_ref(icip_pcs)\n","    pc.partition()\n","    pc.load_tree()\n","for pc in tqdm(icip_pcs):\n","    pc.load_dists_ngbs()\n","    pc.compute_features()\n","    pc.find_shared_blocks()"]},{"cell_type":"code","execution_count":null,"id":"d0521c65","metadata":{"id":"d0521c65"},"outputs":[],"source":["icip_partitions = {}\n","for name in pc_names:\n","    icip_block_names = []\n","    test_names = []\n","    for pc in icip_pcs:\n","        if pc.pc_name != name and pc.is_ref == False :\n","            for block in pc.shared_blocks:\n","                icip_block_names.append([pc.id, block])\n","        if pc.pc_name == name and pc.is_ref == False:\n","            for block in pc.shared_blocks:\n","                test_names.append([pc.id, block])\n","    icip_partitions[name] = {'train' : icip_block_names, 'test' : test_names}"]},{"cell_type":"code","execution_count":null,"id":"75fab63d","metadata":{"id":"75fab63d"},"outputs":[],"source":["filters=32\n","block_shape_modified=(64,64,64,1)\n","params = {'strides': (2, 2, 2), 'padding': 'same', 'use_bias': True}\n","Embedding = tf.keras.Sequential()\n","Embedding.add(tf.keras.layers.Conv3D(name='conv3d_0', filters=32, kernel_size=(5, 5, 5), **params, input_shape=block_shape_modified))\n","Embedding.add(tf.keras.layers.ReLU())\n","Embedding.add(tf.keras.layers.Conv3D(name='conv3d_1', filters=32, kernel_size=(5, 5, 5), **params))\n","Embedding.add(tf.keras.layers.ReLU())\n","Embedding.add(tf.keras.layers.Conv3D(name='conv3d_2', filters=32, kernel_size=(5, 5, 5), **params))\n","Embedding.add(tf.keras.layers.ReLU())\n","Embedding.add(tf.keras.layers.Conv3D(name='conv3d_3', filters=8, kernel_size=(1, 1, 1), activation= tf.keras.activations.relu,strides=(1,1,1)))\n","Embedding.add(tf.keras.layers.Flatten(name='flatten'))"]},{"cell_type":"code","execution_count":null,"id":"be84a79f","metadata":{"id":"be84a79f"},"outputs":[],"source":["right_input = tf.keras.Input((64,64,64,1))\n","left_input = tf.keras.Input((64,64,64,1))\n","right_y = Embedding(right_input)\n","left_y = Embedding(left_input)\n","b = tf.keras.layers.Concatenate()([right_y, left_y]) \n","b = tf.keras.layers.Dropout(rate=0.5)(b)\n","b=tf.keras.layers.Dense(32,activation='relu')(b)\n","b = tf.keras.layers.Dropout(rate=0.5)(b)\n","b=tf.keras.layers.Dense(4,activation='relu')(b)\n","b=tf.keras.layers.Dense(1,activation='relu')(b)\n","Siamese = tf.keras.Model(inputs = [right_input, left_input ], outputs = [b], name=\"siamese\")"]},{"cell_type":"code","execution_count":null,"id":"073e416f","metadata":{"id":"073e416f"},"outputs":[],"source":["def shuffle_and_split(number, train_ratio):\n","    randomlist = np.arange(number)\n","    np.random.shuffle(randomlist)\n","    train_randomlist = randomlist[0:round(number*(1-train_ratio))]\n","    set_randomlist = set(randomlist)\n","    set_train_randomlist = set(train_randomlist) \n","    validation_randomlist = set_randomlist-set_train_randomlist\n","    train_names = np.array(list(set_train_randomlist))\n","    np.random.shuffle(train_names)\n","    validation_names = np.array(list(validation_randomlist))\n","    np.random.shuffle(validation_names)\n","    return train_names, validation_names"]},{"cell_type":"code","execution_count":null,"id":"3ca23c30","metadata":{"id":"3ca23c30"},"outputs":[],"source":["def icip_push_sample (num, name, mode): \n","    num = num.numpy()\n","    name = str(name.numpy(),encoding='ascii')\n","    mode = str(mode.numpy(),encoding='ascii')\n","    pc_id = icip_partitions[name][mode][num][0]\n","    block = icip_partitions[name][mode][num][1]\n","    for pc in icip_pcs:\n","        if pc.id == pc_id :\n","            x1 = pc.blocks_meta[block]['block']\n","            x2 = pc.ref.blocks_meta[block]['block']\n","            mos = pc.mos/5\n","    zeros1 = np.zeros(block_shape, dtype=np.float32)\n","    x1 = pts_to_vx(x1, block_shape, zeros1)\n","    x1 = x1.reshape([64,64,64,1])\n","    zeros2 = np.zeros(block_shape, dtype=np.float32)\n","    x2 = pts_to_vx(x2, block_shape, zeros2)\n","    x2 = x2.reshape([64,64,64,1])\n","    return x1, x2, mos\n","def tf_icip_push_sample (num, name, mode):\n","    return tf.py_function(icip_push_sample, [num, name, mode], [tf.float32, tf.float32, tf.float32])\n","def icip_divide_sample (x1, x2, d2):\n","    return ((x1, x2), d2)"]},{"cell_type":"code","execution_count":null,"id":"ce8439e1","metadata":{"id":"ce8439e1"},"outputs":[],"source":["def initialize_weights(model, weights=None):\n","    if weights is None:\n","        weights = model.get_weights()\n","    initializer = tf.keras.initializers.HeUniform()\n","    weights = [initializer(shape = w.shape) for w in weights]\n","    model.set_weights(weights)"]},{"cell_type":"code","execution_count":null,"id":"5143cbda","metadata":{"id":"5143cbda"},"outputs":[],"source":["initial_learning_rate = 1e-03\n","def lr_exp_decay(epoch, lr):\n","    k = 0.1\n","    return initial_learning_rate * tf.math.exp(-k*epoch)"]},{"cell_type":"code","execution_count":null,"id":"b2fa50c0","metadata":{"id":"b2fa50c0"},"outputs":[],"source":["for pc in icip_pcs: pc.sum_var = 0\n","    \n","for name in tqdm(icip_partitions.keys()):\n","    \n","    icip_block_names = icip_partitions[name]['train']\n","    train_index, val_index = shuffle_and_split(len(icip_block_names), 0.1)\n","    train_dataset = tf.data.Dataset.from_tensor_slices(train_index)#.take(3)\n","    name_dataset = tf.data.Dataset.from_tensor_slices(np.asarray([name for i in range(len(train_index))]))\n","    mode_dataset = tf.data.Dataset.from_tensor_slices(np.asarray(['train' for i in range(len(train_index))]))\n","    icip_dataset = tf.data.Dataset.zip((train_dataset, name_dataset, mode_dataset))\n","    icip_dataset = icip_dataset.map(tf_icip_push_sample, num_parallel_calls = 64)\n","    icip_dataset = icip_dataset.map(icip_divide_sample, num_parallel_calls = 64)\n","    icip_dataset = icip_dataset.batch(64).prefetch(1)\n","    \n","    val_dataset = tf.data.Dataset.from_tensor_slices(val_index)\n","    icip_dataset_val = tf.data.Dataset.zip((val_dataset, name_dataset, mode_dataset))\n","    icip_dataset_val = icip_dataset_val.map(tf_icip_push_sample, num_parallel_calls = 64)\n","    icip_dataset_val = icip_dataset_val.map(icip_divide_sample, num_parallel_calls = 64)\n","    icip_dataset_val = icip_dataset_val.batch(64).prefetch(1)   \n","    initialize_weights(Siamese)\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n","    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3)\n","    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_exp_decay, verbose=0)\n","    Siamese.trainable = True\n","    Siamese.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-03), loss=tf.keras.losses.MeanSquaredError()) \n","    history = Siamese.fit(icip_dataset, epochs=100, callbacks=[callback,reduce_lr,lr_scheduler], initial_epoch=0 ,validation_data=icip_dataset_val)\n","    \n","    Siamese.trainable = False\n","    Siamese.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n","    test_names = icip_partitions[name]['test']\n","    mode_dataset = tf.data.Dataset.from_tensor_slices(np.asarray(['test' for i in range(len(test_names))]))\n","    test_dataset = tf.data.Dataset.from_tensor_slices(np.arange(len(test_names)))#.take(3)\n","    icip_dataset_test = tf.data.Dataset.zip((test_dataset, name_dataset, mode_dataset))\n","    icip_dataset_test = icip_dataset_test.map(tf_icip_push_sample, num_parallel_calls = 128)\n","    icip_dataset_test = icip_dataset_test.map(icip_divide_sample, num_parallel_calls = 128)\n","    icip_dataset_test = icip_dataset_test.batch(128).prefetch(1)\n","    predictions = Siamese.predict(icip_dataset_test)\n","    icip_partitions[name]['predictions'] = predictions\n","    \n","    for i, elem in enumerate(test_names):\n","        for pc in icip_pcs :\n","            if pc.id == elem[0] :\n","                pc.sum_var = pc.sum_var + predictions[i]"]},{"cell_type":"code","execution_count":null,"id":"90729f50","metadata":{"id":"90729f50"},"outputs":[],"source":["mos_list = np.reshape(np.asarray([pc.mos for pc in icip_pcs if pc.is_ref == False][0:75]), -1)\n","preidctions_list = np.reshape(np.asarray([pc.sum_var/len(pc.shared_blocks) for pc in icip_pcs if pc.is_ref == False][0:75]), -1)"]},{"cell_type":"code","execution_count":null,"id":"233b590f","metadata":{"id":"233b590f"},"outputs":[],"source":["plcc=scipy.stats.pearsonr(mos_list, preidctions_list)\n","srocc=scipy.stats.spearmanr(mos_list, preidctions_list)"]},{"cell_type":"code","execution_count":null,"id":"b08228d2","metadata":{"id":"b08228d2","outputId":"519ec279-552a-44ed-fc8e-d95c63a2a010"},"outputs":[{"name":"stdout","output_type":"stream","text":["(0.8356561950371263, 1.1160330465589438e-20)\n","SpearmanrResult(correlation=0.8348971058303803, pvalue=1.3018166846360089e-20)\n"]}],"source":["print(plcc)\n","print(srocc)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"reseau_1.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}